{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "from sklearn.metrics import fbeta_score\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/data/amazon/train-jpg/'\n",
    "TEST_PATH = '/data/amazon/test-jpg/'\n",
    "train_df = pd.read_csv('/data/amazon/train_v2.csv')\n",
    "test_df = pd.read_csv('/data/amazon/sample_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df, data_path):\n",
    "    im_features = df.copy()\n",
    "    N = len(im_features.image_name.values)\n",
    "    \n",
    "    r_mean = np.zeros(N)\n",
    "    g_mean = np.zeros(N)\n",
    "    b_mean = np.zeros(N)\n",
    "    \n",
    "    r_std = np.zeros(N)\n",
    "    g_std = np.zeros(N)\n",
    "    b_std = np.zeros(N)\n",
    "    \n",
    "    r_max = np.zeros(N)\n",
    "    g_max = np.zeros(N)\n",
    "    b_max = np.zeros(N)\n",
    "    \n",
    "    r_min = np.zeros(N)\n",
    "    g_min = np.zeros(N)\n",
    "    b_min = np.zeros(N)\n",
    "    \n",
    "    r_kurtosis = np.zeros(N)\n",
    "    g_kurtosis = np.zeros(N)\n",
    "    b_kurtosis = np.zeros(N)\n",
    "    \n",
    "    r_skewness = np.zeros(N)\n",
    "    g_skewness = np.zeros(N)\n",
    "    b_skewness = np.zeros(N)\n",
    "    \n",
    "    for i, image_name in enumerate(tqdm(im_features.image_name.values, miniters=1000)):\n",
    "        im = Image.open(data_path + image_name + '.jpg')\n",
    "        im = np.array(im)[:,:,:3]\n",
    "        \n",
    "        r = im[:,:,0].ravel()\n",
    "        g = im[:,:,1].ravel()\n",
    "        b = im[:,:,2].ravel()\n",
    "        \n",
    "        r_mean[i] = np.mean(r)\n",
    "        g_mean[i] = np.mean(g)\n",
    "        b_mean[i] = np.mean(b)\n",
    "        \n",
    "        r_std[i] = np.std(r)\n",
    "        g_std[i] = np.std(g)\n",
    "        b_std[i] = np.std(b)\n",
    "        \n",
    "        r_max[i] = np.max(r)\n",
    "        g_max[i] = np.max(g)\n",
    "        b_max[i] = np.max(b)\n",
    "        \n",
    "        r_min[i] = np.min(r)\n",
    "        g_min[i] = np.min(g)\n",
    "        b_min[i] = np.min(b)\n",
    "        \n",
    "        r_kurtosis[i] = scipy.stats.kurtosis(r)\n",
    "        g_kurtosis[i] = scipy.stats.kurtosis(g)\n",
    "        b_kurtosis[i] = scipy.stats.kurtosis(b)\n",
    "        \n",
    "        r_skewness[i] = scipy.stats.skew(r)\n",
    "        g_skewness[i] = scipy.stats.skew(g)\n",
    "        b_skewness[i] = scipy.stats.skew(b)\n",
    "        \n",
    "    im_features['r_mean'] = r_mean\n",
    "    im_features['g_mean'] = g_mean\n",
    "    im_features['b_mean'] = b_mean\n",
    "    \n",
    "    im_features['rgb_mean_mean'] = (r_mean + g_mean + b_mean)/3\n",
    "    \n",
    "    im_features['r_std'] = r_std\n",
    "    im_features['g_std'] = g_std\n",
    "    im_features['b_std'] = b_std\n",
    "    \n",
    "    im_features['rgb_mean_std'] = (r_std + g_std + b_std)/3\n",
    "    \n",
    "    im_features['r_max'] = r_max\n",
    "    im_features['g_max'] = g_max\n",
    "    im_features['b_max'] = b_max\n",
    "    \n",
    "    im_features['rgb_mean_max'] = (r_max + g_max + b_max)/3\n",
    "    \n",
    "    im_features['r_min'] = r_min\n",
    "    im_features['g_min'] = g_min\n",
    "    im_features['b_min'] = b_min\n",
    "    \n",
    "    im_features['rgb_mean_min'] = (r_min + g_min + b_min)/3\n",
    "    \n",
    "    im_features['r_range'] = r_max - r_min\n",
    "    im_features['g_range'] = g_max - g_min\n",
    "    im_features['b_range'] = b_max - b_min\n",
    "    \n",
    "    im_features['r_kurtosis'] = r_kurtosis\n",
    "    im_features['g_kurtosis'] = g_kurtosis\n",
    "    im_features['b_kurtosis'] = b_kurtosis\n",
    "    \n",
    "    im_features['r_skewness'] = r_skewness\n",
    "    im_features['g_skewness'] = g_skewness\n",
    "    im_features['b_skewness'] = b_skewness\n",
    "    \n",
    "    return im_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40479 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [06:30<00:00, 103.62it/s]\n",
      "  0%|          | 0/61191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61191/61191 [13:28<00:00, 75.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "print('Extracting train features')\n",
    "train_features = extract_features(train_df, TRAIN_PATH)\n",
    "print('Extracting test features')\n",
    "test_features = extract_features(test_df, TEST_PATH)\n",
    "\n",
    "# Prepare data\n",
    "X = np.array(train_features.drop(['image_name', 'tags'], axis=1))\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = np.array(list(set(flatten([l.split(' ') for l in train_features['tags'].values]))))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 238269.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for tags in tqdm(train_df.tags.values, miniters=1000):\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    y_train.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (40479, 25)\n",
      "y.shape = (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(y_train, np.uint8)\n",
    "\n",
    "print('X.shape = ' + str(X.shape))\n",
    "print('y.shape = ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = y.shape[1]\n",
    "\n",
    "X_test = np.array(test_features.drop(['image_name', 'tags'], axis=1))\n",
    "\n",
    "# Train and predict with one-vs-all strategy\n",
    "y_pred = np.zeros((X_test.shape[0], n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:17<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "print('Training and making predictions')\n",
    "for class_i in tqdm(range(n_classes), miniters=1): \n",
    "    model = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=100,\n",
    "                              silent=True, objective='binary:logistic', nthread=-1,\n",
    "                              gamma=0, min_child_weight=1, max_delta_step=0, \n",
    "                              subsample=1, colsample_bytree=1, colsample_bylevel=1,\n",
    "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "                              base_score=0.5, seed=random_seed, missing=None)\n",
    "    model.fit(X, y[:, class_i])\n",
    "    y_pred[:, class_i] = model.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = [' '.join(labels[y_pred_row > 0.21]) for y_pred_row in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = test_features.image_name.values\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p_valid = model.predict(x_valid, batch_size=128)\n",
    "# print(y_valid)\n",
    "# print(p_valid)\n",
    "# print(fbeta_score(y_valid, y_pred > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
